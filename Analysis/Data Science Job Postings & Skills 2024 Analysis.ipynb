{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eaf8ecaa-ff98-4150-a071-f099db9ff020",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dependencies and Setup\n",
    "from api_keys import KAGGLE_USERNAME, KAGGLE_KEY\n",
    "import os\n",
    "import json\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "\n",
    "#Set environment variables for Kaggle API\n",
    "os.environ[\"KAGGLE_USERNAME\"] = KAGGLE_USERNAME\n",
    "os.environ[\"KAGGLE_KEY\"] = KAGGLE_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08f6862c-63e9-4c64-b0be-a6c0b4be0862",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'kagglehub' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Download latest version\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m path \u001b[38;5;241m=\u001b[39m kagglehub\u001b[38;5;241m.\u001b[39mdataset_download(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124masaniczka/data-science-job-postings-and-skills\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPath to dataset files:\u001b[39m\u001b[38;5;124m\"\u001b[39m, path)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'kagglehub' is not defined"
     ]
    }
   ],
   "source": [
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"asaniczka/data-science-job-postings-and-skills\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81617fa4-4bdb-4cae-a5a2-7dee83fb1e17",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../Database/job_postings.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Load CSV files\u001b[39;00m\n\u001b[1;32m      2\u001b[0m job_skills_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../Database/job_skills.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m job_postings_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../Database/job_postings.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m pd\u001b[38;5;241m.\u001b[39mset_option(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdisplay.max_columns\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Merge job_postings and job_skills dataframes on the 'job_link' column\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[1;32m   1881\u001b[0m     f,\n\u001b[1;32m   1882\u001b[0m     mode,\n\u001b[1;32m   1883\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1884\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1885\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m   1886\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[1;32m   1887\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1888\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1889\u001b[0m )\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    874\u001b[0m             handle,\n\u001b[1;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[1;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    879\u001b[0m         )\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../Database/job_postings.csv'"
     ]
    }
   ],
   "source": [
    "# Load CSV files\n",
    "job_skills_df = pd.read_csv(\"../Database/job_skills.csv\")\n",
    "job_postings_df = pd.read_csv(\"../Database/job_postings.csv\")\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Merge job_postings and job_skills dataframes on the 'job_link' column\n",
    "job_skills_postings_merged_df = pd.merge(job_postings_df, job_skills_df, on='job_link', how='inner')\n",
    "job_skills_postings_merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d643de31-c9dc-4c1f-9043-cb0979e9d29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove unwanted columns\n",
    "job_skills_postings_df = job_skills_postings_merged_df[['job_title',\n",
    "                                                        'company',\n",
    "                                                        'job_location',\n",
    "                                                        'first_seen',\n",
    "                                                        'search_country',\n",
    "                                                        'search_position',\n",
    "                                                        'job_level',\n",
    "                                                        'job_type',\n",
    "                                                        'job_skills'\n",
    "                                                       ]]\n",
    "job_skills_postings_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28091437-2ccc-4ff6-ace2-930a2dca78c2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'job_skills_postings_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m job_skills_postings_df\u001b[38;5;241m.\u001b[39mcount()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'job_skills_postings_df' is not defined"
     ]
    }
   ],
   "source": [
    "job_skills_postings_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "452ef96b-4052-400e-ac9a-6bc2eb8f87f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Job Location</th>\n",
       "      <th>Job Location City</th>\n",
       "      <th>Job Location State</th>\n",
       "      <th>Job Posting Seen</th>\n",
       "      <th>Country</th>\n",
       "      <th>Position</th>\n",
       "      <th>Job Level</th>\n",
       "      <th>Job Type</th>\n",
       "      <th>Job Skills</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senior Machine Learning Engineer</td>\n",
       "      <td>Jobs for Humanity</td>\n",
       "      <td>New Haven, CT</td>\n",
       "      <td>New Haven</td>\n",
       "      <td>CT</td>\n",
       "      <td>2024-01-14</td>\n",
       "      <td>United States</td>\n",
       "      <td>Agricultural-Research Engineer</td>\n",
       "      <td>Mid senior</td>\n",
       "      <td>Onsite</td>\n",
       "      <td>Machine Learning, Programming, Python, Scala, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Principal Software Engineer, ML Accelerators</td>\n",
       "      <td>Aurora</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>CA</td>\n",
       "      <td>2024-01-14</td>\n",
       "      <td>United States</td>\n",
       "      <td>Set-Key Driver</td>\n",
       "      <td>Mid senior</td>\n",
       "      <td>Onsite</td>\n",
       "      <td>C++, Python, PyTorch, TensorFlow, MXNet, CUDA,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior ETL Data Warehouse Specialist</td>\n",
       "      <td>Adame Services LLC</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>2024-01-14</td>\n",
       "      <td>United States</td>\n",
       "      <td>Technical Support Specialist</td>\n",
       "      <td>Associate</td>\n",
       "      <td>Onsite</td>\n",
       "      <td>ETL, Data Integration, Data Transformation, Da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Senior Data Warehouse Developer / Architect</td>\n",
       "      <td>Morph Enterprise</td>\n",
       "      <td>Harrisburg, PA</td>\n",
       "      <td>Harrisburg</td>\n",
       "      <td>PA</td>\n",
       "      <td>2024-01-12</td>\n",
       "      <td>United States</td>\n",
       "      <td>Architect</td>\n",
       "      <td>Mid senior</td>\n",
       "      <td>Onsite</td>\n",
       "      <td>Data Lakes, Data Bricks, Azure Data Factory Pi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lead Data Engineer</td>\n",
       "      <td>Dice</td>\n",
       "      <td>Plano, TX</td>\n",
       "      <td>Plano</td>\n",
       "      <td>TX</td>\n",
       "      <td>2024-01-14</td>\n",
       "      <td>United States</td>\n",
       "      <td>Maintenance Data Analyst</td>\n",
       "      <td>Mid senior</td>\n",
       "      <td>Onsite</td>\n",
       "      <td>Java, Scala, Python, RDBMS, NoSQL, Redshift, S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12212</th>\n",
       "      <td>Data Reporting Manager, FOOTBALL ASSOCIATION</td>\n",
       "      <td>Guardian Jobs</td>\n",
       "      <td>Wembley, England, United Kingdom</td>\n",
       "      <td>Wembley</td>\n",
       "      <td>England, United Kingdom</td>\n",
       "      <td>2024-01-16</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Manager Forms Analysis</td>\n",
       "      <td>Mid senior</td>\n",
       "      <td>Onsite</td>\n",
       "      <td>Dashboard development, Reporting, Power BI, SQ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12213</th>\n",
       "      <td>Corporate AML Alert Investigation Specialist</td>\n",
       "      <td>Glacier Bancorp, Inc.</td>\n",
       "      <td>Kalispell, MT</td>\n",
       "      <td>Kalispell</td>\n",
       "      <td>MT</td>\n",
       "      <td>2024-01-14</td>\n",
       "      <td>United States</td>\n",
       "      <td>Teller</td>\n",
       "      <td>Mid senior</td>\n",
       "      <td>Onsite</td>\n",
       "      <td>Investigation, Antimoney laundering, Fraud, Ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12214</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Highnote</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>CA</td>\n",
       "      <td>2024-01-16</td>\n",
       "      <td>United States</td>\n",
       "      <td>Mathematician</td>\n",
       "      <td>Mid senior</td>\n",
       "      <td>Onsite</td>\n",
       "      <td>Data Science, Quantitative Modeling, SQL, Data...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12215</th>\n",
       "      <td>Senior Data Engineer</td>\n",
       "      <td>CompSource Mutual Insurance Company</td>\n",
       "      <td>Oklahoma City, OK</td>\n",
       "      <td>Oklahoma City</td>\n",
       "      <td>OK</td>\n",
       "      <td>2024-01-16</td>\n",
       "      <td>United States</td>\n",
       "      <td>Protection Engineer</td>\n",
       "      <td>Mid senior</td>\n",
       "      <td>Onsite</td>\n",
       "      <td>Data Engineering, Data Quality, SQL, Python, T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12216</th>\n",
       "      <td>Medical Technologist, MLS or MLT</td>\n",
       "      <td>Community Health Systems</td>\n",
       "      <td>Mooresville, NC</td>\n",
       "      <td>Mooresville</td>\n",
       "      <td>NC</td>\n",
       "      <td>2024-01-14</td>\n",
       "      <td>United States</td>\n",
       "      <td>Biologist</td>\n",
       "      <td>Mid senior</td>\n",
       "      <td>Onsite</td>\n",
       "      <td>Medical Technology, MLS, Microbiology, Clinica...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12217 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Job Title  \\\n",
       "0                  Senior Machine Learning Engineer   \n",
       "1      Principal Software Engineer, ML Accelerators   \n",
       "2              Senior ETL Data Warehouse Specialist   \n",
       "3       Senior Data Warehouse Developer / Architect   \n",
       "4                                Lead Data Engineer   \n",
       "...                                             ...   \n",
       "12212  Data Reporting Manager, FOOTBALL ASSOCIATION   \n",
       "12213  Corporate AML Alert Investigation Specialist   \n",
       "12214                         Senior Data Scientist   \n",
       "12215                          Senior Data Engineer   \n",
       "12216              Medical Technologist, MLS or MLT   \n",
       "\n",
       "                                   Company                      Job Location  \\\n",
       "0                        Jobs for Humanity                     New Haven, CT   \n",
       "1                                   Aurora                 San Francisco, CA   \n",
       "2                       Adame Services LLC                      New York, NY   \n",
       "3                         Morph Enterprise                    Harrisburg, PA   \n",
       "4                                     Dice                         Plano, TX   \n",
       "...                                    ...                               ...   \n",
       "12212                        Guardian Jobs  Wembley, England, United Kingdom   \n",
       "12213                Glacier Bancorp, Inc.                     Kalispell, MT   \n",
       "12214                             Highnote                 San Francisco, CA   \n",
       "12215  CompSource Mutual Insurance Company                 Oklahoma City, OK   \n",
       "12216             Community Health Systems                   Mooresville, NC   \n",
       "\n",
       "      Job Location City       Job Location State Job Posting Seen  \\\n",
       "0             New Haven                       CT       2024-01-14   \n",
       "1         San Francisco                       CA       2024-01-14   \n",
       "2              New York                       NY       2024-01-14   \n",
       "3            Harrisburg                       PA       2024-01-12   \n",
       "4                 Plano                       TX       2024-01-14   \n",
       "...                 ...                      ...              ...   \n",
       "12212           Wembley  England, United Kingdom       2024-01-16   \n",
       "12213         Kalispell                       MT       2024-01-14   \n",
       "12214     San Francisco                       CA       2024-01-16   \n",
       "12215     Oklahoma City                       OK       2024-01-16   \n",
       "12216       Mooresville                       NC       2024-01-14   \n",
       "\n",
       "              Country                        Position   Job Level Job Type  \\\n",
       "0       United States  Agricultural-Research Engineer  Mid senior   Onsite   \n",
       "1       United States                  Set-Key Driver  Mid senior   Onsite   \n",
       "2       United States    Technical Support Specialist   Associate   Onsite   \n",
       "3       United States                       Architect  Mid senior   Onsite   \n",
       "4       United States        Maintenance Data Analyst  Mid senior   Onsite   \n",
       "...               ...                             ...         ...      ...   \n",
       "12212  United Kingdom          Manager Forms Analysis  Mid senior   Onsite   \n",
       "12213   United States                          Teller  Mid senior   Onsite   \n",
       "12214   United States                   Mathematician  Mid senior   Onsite   \n",
       "12215   United States             Protection Engineer  Mid senior   Onsite   \n",
       "12216   United States                       Biologist  Mid senior   Onsite   \n",
       "\n",
       "                                              Job Skills  \n",
       "0      Machine Learning, Programming, Python, Scala, ...  \n",
       "1      C++, Python, PyTorch, TensorFlow, MXNet, CUDA,...  \n",
       "2      ETL, Data Integration, Data Transformation, Da...  \n",
       "3      Data Lakes, Data Bricks, Azure Data Factory Pi...  \n",
       "4      Java, Scala, Python, RDBMS, NoSQL, Redshift, S...  \n",
       "...                                                  ...  \n",
       "12212  Dashboard development, Reporting, Power BI, SQ...  \n",
       "12213  Investigation, Antimoney laundering, Fraud, Ba...  \n",
       "12214  Data Science, Quantitative Modeling, SQL, Data...  \n",
       "12215  Data Engineering, Data Quality, SQL, Python, T...  \n",
       "12216  Medical Technology, MLS, Microbiology, Clinica...  \n",
       "\n",
       "[12217 rows x 11 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Rename columns\n",
    "job_skills_postings_df = job_skills_postings_df.rename(columns={\"job_title\": \"Job Title\",\n",
    "                                                        \"company\": \"Company\",\n",
    "                                                        \"job_location\": \"Job Location\",\n",
    "                                                        \"first_seen\": \"Job Posting Seen\",\n",
    "                                                        \"search_country\": \"Country\",\n",
    "                                                        \"search_position\": \"Position\",\n",
    "                                                        \"job_level\": \"Job Level\",\n",
    "                                                        \"job_type\": \"Job Type\",\n",
    "                                                        \"job_skills\": \"Job Skills\"\n",
    "                                                               })\n",
    "\n",
    "# Ensure all entries in 'Job Location' are strings for consistent splitting\n",
    "job_skills_postings_df['Job Location'] = job_skills_postings_df['Job Location'].astype(str)\n",
    "\n",
    "# Split 'Job Location' into 'Job Location City' and 'Job Location State'\n",
    "split_location = job_skills_postings_df['Job Location'].str.split(', ', n=1, expand=True)\n",
    "job_skills_postings_df['Job Location City'] = split_location[0]\n",
    "job_skills_postings_df['Job Location State'] = split_location[1]\n",
    "\n",
    "# Reorder columns to place 'Job Location City' and 'Job Location State' after 'Job Location'\n",
    "columns = list(job_skills_postings_df.columns)\n",
    "new_order = columns[:3] + ['Job Location City', 'Job Location State'] + columns[3:-2]\n",
    "job_skills_postings_df = job_skills_postings_df[new_order]\n",
    "\n",
    "job_skills_postings_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f162ebef-9877-4ccc-9f3b-b200b46dfa3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object\n"
     ]
    }
   ],
   "source": [
    "print(job_skills_postings_df[\"Job Posting Seen\"].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "62334419-ab8a-420c-827e-3a1a0ab2c0f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "# Convert 'Job Posting Seen' to datetime format\n",
    "job_skills_postings_df[\"Job Posting Seen\"] = pd.to_datetime(job_skills_postings_df[\"Job Posting Seen\"])\n",
    "print(job_skills_postings_df[\"Job Posting Seen\"].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c23d1c89-0d58-4f5f-ae7c-c46276e5b318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country\n",
      "United States     10291\n",
      "United Kingdom      995\n",
      "Canada              630\n",
      "Australia           301\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "country_counts = job_skills_postings_df['Country'].value_counts()\n",
    "print(country_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b59eca9c-23b7-4719-ad66-a32c50d00c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country\n",
      "United States    10291\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Filter the DataFrame for rows where Country is 'United States'\n",
    "us_job_skills_df = job_skills_postings_df[job_skills_postings_df[\"Country\"] == \"United States\"]\n",
    "us_job_skills_counts = us_job_skills_df['Country'].value_counts()\n",
    "print(us_job_skills_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "85e4173c-81d1-4edc-81d8-9eb5428afef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    Machine Learning, Programming, Python, Scala, ...\n",
      "1    C++, Python, PyTorch, TensorFlow, MXNet, CUDA,...\n",
      "2    ETL, Data Integration, Data Transformation, Da...\n",
      "3    Data Lakes, Data Bricks, Azure Data Factory Pi...\n",
      "4    Java, Scala, Python, RDBMS, NoSQL, Redshift, S...\n",
      "Name: Job Skills, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Display the first few rows of the 'Job Skills' column to inspect the structure\n",
    "print(us_job_skills_df[\"Job Skills\"].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "33e3585e-6029-4d23-971e-161d8964c814",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split 'Job Skills' by comma in the filtered DataFrame\n",
    "us_job_skills_df.loc[:, \"Job Skills\"] = us_job_skills_df[\"Job Skills\"].str.split(\",\")\n",
    "\n",
    "# Explode to create a new row for each skill\n",
    "skills_df = us_job_skills_df.explode(\"Job Skills\")\n",
    "\n",
    "# Strip whitespace around each skill\n",
    "skills_df[\"Job Skills\"] = skills_df[\"Job Skills\"].str.strip()\n",
    "\n",
    "# Drop any empty strings that may remain\n",
    "skills_df = skills_df[skills_df[\"Job Skills\"] != \"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6f118294-242f-4f28-83a1-1f6cf42e9f90",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job Skills\n",
      "Python                4071\n",
      "SQL                   3855\n",
      "Communication         2013\n",
      "Data Analysis         1762\n",
      "Machine Learning      1694\n",
      "AWS                   1561\n",
      "Tableau               1394\n",
      "Java                  1281\n",
      "R                     1275\n",
      "Data Visualization    1261\n",
      "Spark                 1229\n",
      "Data Science          1098\n",
      "Data Engineering      1065\n",
      "Project Management    1023\n",
      "Teamwork               982\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Count occurrences of each skill and get the top 15\n",
    "top_skills = skills_df[\"Job Skills\"].value_counts().head(15)\n",
    "print(top_skills)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b27c315b-7387-43d2-b648-4cb48e4600e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Job Location</th>\n",
       "      <th>Job Location City</th>\n",
       "      <th>Job Location State</th>\n",
       "      <th>Job Posting Seen</th>\n",
       "      <th>Country</th>\n",
       "      <th>Position</th>\n",
       "      <th>Job Level</th>\n",
       "      <th>Job Type</th>\n",
       "      <th>Job Skills</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senior Machine Learning Engineer</td>\n",
       "      <td>Jobs for Humanity</td>\n",
       "      <td>New Haven, CT</td>\n",
       "      <td>New Haven</td>\n",
       "      <td>CT</td>\n",
       "      <td>2024-01-14</td>\n",
       "      <td>United States</td>\n",
       "      <td>Agricultural-Research Engineer</td>\n",
       "      <td>Mid senior</td>\n",
       "      <td>Onsite</td>\n",
       "      <td>Machine Learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senior Machine Learning Engineer</td>\n",
       "      <td>Jobs for Humanity</td>\n",
       "      <td>New Haven, CT</td>\n",
       "      <td>New Haven</td>\n",
       "      <td>CT</td>\n",
       "      <td>2024-01-14</td>\n",
       "      <td>United States</td>\n",
       "      <td>Agricultural-Research Engineer</td>\n",
       "      <td>Mid senior</td>\n",
       "      <td>Onsite</td>\n",
       "      <td>Programming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senior Machine Learning Engineer</td>\n",
       "      <td>Jobs for Humanity</td>\n",
       "      <td>New Haven, CT</td>\n",
       "      <td>New Haven</td>\n",
       "      <td>CT</td>\n",
       "      <td>2024-01-14</td>\n",
       "      <td>United States</td>\n",
       "      <td>Agricultural-Research Engineer</td>\n",
       "      <td>Mid senior</td>\n",
       "      <td>Onsite</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senior Machine Learning Engineer</td>\n",
       "      <td>Jobs for Humanity</td>\n",
       "      <td>New Haven, CT</td>\n",
       "      <td>New Haven</td>\n",
       "      <td>CT</td>\n",
       "      <td>2024-01-14</td>\n",
       "      <td>United States</td>\n",
       "      <td>Agricultural-Research Engineer</td>\n",
       "      <td>Mid senior</td>\n",
       "      <td>Onsite</td>\n",
       "      <td>Scala</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senior Machine Learning Engineer</td>\n",
       "      <td>Jobs for Humanity</td>\n",
       "      <td>New Haven, CT</td>\n",
       "      <td>New Haven</td>\n",
       "      <td>CT</td>\n",
       "      <td>2024-01-14</td>\n",
       "      <td>United States</td>\n",
       "      <td>Agricultural-Research Engineer</td>\n",
       "      <td>Mid senior</td>\n",
       "      <td>Onsite</td>\n",
       "      <td>Java</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Job Title            Company   Job Location  \\\n",
       "0  Senior Machine Learning Engineer  Jobs for Humanity  New Haven, CT   \n",
       "0  Senior Machine Learning Engineer  Jobs for Humanity  New Haven, CT   \n",
       "0  Senior Machine Learning Engineer  Jobs for Humanity  New Haven, CT   \n",
       "0  Senior Machine Learning Engineer  Jobs for Humanity  New Haven, CT   \n",
       "0  Senior Machine Learning Engineer  Jobs for Humanity  New Haven, CT   \n",
       "\n",
       "  Job Location City Job Location State Job Posting Seen        Country  \\\n",
       "0         New Haven                 CT       2024-01-14  United States   \n",
       "0         New Haven                 CT       2024-01-14  United States   \n",
       "0         New Haven                 CT       2024-01-14  United States   \n",
       "0         New Haven                 CT       2024-01-14  United States   \n",
       "0         New Haven                 CT       2024-01-14  United States   \n",
       "\n",
       "                         Position   Job Level Job Type        Job Skills  \n",
       "0  Agricultural-Research Engineer  Mid senior   Onsite  Machine Learning  \n",
       "0  Agricultural-Research Engineer  Mid senior   Onsite       Programming  \n",
       "0  Agricultural-Research Engineer  Mid senior   Onsite            Python  \n",
       "0  Agricultural-Research Engineer  Mid senior   Onsite             Scala  \n",
       "0  Agricultural-Research Engineer  Mid senior   Onsite              Java  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skills_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d182662d-c4ae-4781-9ba5-66a80ecde48a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job Skills\n",
      "Python                4071\n",
      "SQL                   3855\n",
      "Communication         2013\n",
      "Data Analysis         1762\n",
      "Machine Learning      1694\n",
      "AWS                   1561\n",
      "Tableau               1394\n",
      "Java                  1281\n",
      "R                     1275\n",
      "Data Visualization    1261\n",
      "Spark                 1229\n",
      "Data Science          1098\n",
      "Data Engineering      1065\n",
      "Project Management    1023\n",
      "Teamwork               982\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Count occurrences of each skill and get the top 15\n",
    "top_skills = skills_df[\"Job Skills\"].value_counts().head(15)\n",
    "print(top_skills)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5bcb4bb4-f857-4bac-b9de-965867c805e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Job Location</th>\n",
       "      <th>Job Location City</th>\n",
       "      <th>Job Location State</th>\n",
       "      <th>Job Posting Seen</th>\n",
       "      <th>Country</th>\n",
       "      <th>Position</th>\n",
       "      <th>Job Level</th>\n",
       "      <th>Job Type</th>\n",
       "      <th>Job Skills</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senior Machine Learning Engineer</td>\n",
       "      <td>Jobs for Humanity</td>\n",
       "      <td>New Haven, CT</td>\n",
       "      <td>New Haven</td>\n",
       "      <td>CT</td>\n",
       "      <td>2024-01-14</td>\n",
       "      <td>United States</td>\n",
       "      <td>Agricultural-Research Engineer</td>\n",
       "      <td>Mid senior</td>\n",
       "      <td>Onsite</td>\n",
       "      <td>Machine Learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senior Machine Learning Engineer</td>\n",
       "      <td>Jobs for Humanity</td>\n",
       "      <td>New Haven, CT</td>\n",
       "      <td>New Haven</td>\n",
       "      <td>CT</td>\n",
       "      <td>2024-01-14</td>\n",
       "      <td>United States</td>\n",
       "      <td>Agricultural-Research Engineer</td>\n",
       "      <td>Mid senior</td>\n",
       "      <td>Onsite</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senior Machine Learning Engineer</td>\n",
       "      <td>Jobs for Humanity</td>\n",
       "      <td>New Haven, CT</td>\n",
       "      <td>New Haven</td>\n",
       "      <td>CT</td>\n",
       "      <td>2024-01-14</td>\n",
       "      <td>United States</td>\n",
       "      <td>Agricultural-Research Engineer</td>\n",
       "      <td>Mid senior</td>\n",
       "      <td>Onsite</td>\n",
       "      <td>Data Engineering</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senior Machine Learning Engineer</td>\n",
       "      <td>Jobs for Humanity</td>\n",
       "      <td>New Haven, CT</td>\n",
       "      <td>New Haven</td>\n",
       "      <td>CT</td>\n",
       "      <td>2024-01-14</td>\n",
       "      <td>United States</td>\n",
       "      <td>Agricultural-Research Engineer</td>\n",
       "      <td>Mid senior</td>\n",
       "      <td>Onsite</td>\n",
       "      <td>Data Visualization</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Principal Software Engineer, ML Accelerators</td>\n",
       "      <td>Aurora</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>CA</td>\n",
       "      <td>2024-01-14</td>\n",
       "      <td>United States</td>\n",
       "      <td>Set-Key Driver</td>\n",
       "      <td>Mid senior</td>\n",
       "      <td>Onsite</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Job Title            Company  \\\n",
       "0              Senior Machine Learning Engineer  Jobs for Humanity   \n",
       "0              Senior Machine Learning Engineer  Jobs for Humanity   \n",
       "0              Senior Machine Learning Engineer  Jobs for Humanity   \n",
       "0              Senior Machine Learning Engineer  Jobs for Humanity   \n",
       "1  Principal Software Engineer, ML Accelerators             Aurora   \n",
       "\n",
       "        Job Location Job Location City Job Location State Job Posting Seen  \\\n",
       "0      New Haven, CT         New Haven                 CT       2024-01-14   \n",
       "0      New Haven, CT         New Haven                 CT       2024-01-14   \n",
       "0      New Haven, CT         New Haven                 CT       2024-01-14   \n",
       "0      New Haven, CT         New Haven                 CT       2024-01-14   \n",
       "1  San Francisco, CA     San Francisco                 CA       2024-01-14   \n",
       "\n",
       "         Country                        Position   Job Level Job Type  \\\n",
       "0  United States  Agricultural-Research Engineer  Mid senior   Onsite   \n",
       "0  United States  Agricultural-Research Engineer  Mid senior   Onsite   \n",
       "0  United States  Agricultural-Research Engineer  Mid senior   Onsite   \n",
       "0  United States  Agricultural-Research Engineer  Mid senior   Onsite   \n",
       "1  United States                  Set-Key Driver  Mid senior   Onsite   \n",
       "\n",
       "           Job Skills  \n",
       "0    Machine Learning  \n",
       "0              Python  \n",
       "0    Data Engineering  \n",
       "0  Data Visualization  \n",
       "1              Python  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List of top job skills, filtering by top 10 hard skill\n",
    "top_skills = ['Python', 'SQL', 'Data Analysis', 'Machine Learning', 'Data Visualization', 'AWS', 'Project Management', 'Data Science', 'Data Engineering', 'Tableau']  # Replace with your actual skills\n",
    "\n",
    "# Filter the original DataFrame to include only rows with these specific job skills\n",
    "filtered_top_skills_df = skills_df[skills_df[\"Job Skills\"].isin(top_skills)]\n",
    "\n",
    "# Print the filtered DataFrame\n",
    "filtered_top_skills_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fdd34f35-80ce-4c26-9b90-656719486cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export data to csv\n",
    "filtered_top_skills_df.to_csv('us_top_job_skills.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a4a8cc53-0a7a-4e81-8b4f-62e43b184f87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 18784\n"
     ]
    }
   ],
   "source": [
    "row_count = len(filtered_top_skills_df)\n",
    "print(f\"Number of rows: {row_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "58454e79-43e7-45d9-8b5f-54d5bc33fd6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job Skills\n",
      "Python                4071\n",
      "SQL                   3855\n",
      "Data Analysis         1762\n",
      "Machine Learning      1694\n",
      "AWS                   1561\n",
      "Tableau               1394\n",
      "Data Visualization    1261\n",
      "Data Science          1098\n",
      "Data Engineering      1065\n",
      "Project Management    1023\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Count occurrences of top 10 skills\n",
    "top10_skills = filtered_top_skills_df[\"Job Skills\"].value_counts()\n",
    "print(top10_skills)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1f453041-d32b-4456-949d-671749a28c79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job Location\n",
      "New York, NY         636\n",
      "San Francisco, CA    522\n",
      "Chicago, IL          492\n",
      "Washington, DC       458\n",
      "Dallas, TX           381\n",
      "Seattle, WA          373\n",
      "Atlanta, GA          308\n",
      "Austin, TX           302\n",
      "Boston, MA           295\n",
      "Houston, TX          265\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Count occurrences of top 10 job locations\n",
    "top10_joblocations = filtered_top_skills_df[\"Job Location\"].value_counts().head(10)\n",
    "print(top10_joblocations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e0faf4b7-95d3-4be7-a019-1c569887fc56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Job Location          Job Skills  Count\n",
      "8      Atlanta, GA                 SQL     64\n",
      "7      Atlanta, GA              Python     53\n",
      "1      Atlanta, GA       Data Analysis     32\n",
      "9      Atlanta, GA             Tableau     30\n",
      "5      Atlanta, GA    Machine Learning     28\n",
      "..             ...                 ...    ...\n",
      "95  Washington, DC    Machine Learning     44\n",
      "90  Washington, DC                 AWS     30\n",
      "93  Washington, DC        Data Science     30\n",
      "96  Washington, DC  Project Management     23\n",
      "92  Washington, DC    Data Engineering     20\n",
      "\n",
      "[100 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Group and count skills by location\n",
    "top10_joblocations = filtered_top_skills_df[\"Job Location\"].value_counts().head(10).index\n",
    "top10_skills_by_location = filtered_top_skills_df[filtered_top_skills_df[\"Job Location\"].isin(top10_joblocations)]\n",
    "\n",
    "# Group by \"Job Location\" and \"Job Skills\", then count occurrences\n",
    "skills_by_location_count = (\n",
    "    top10_skills_by_location.groupby([\"Job Location\", \"Job Skills\"])\n",
    "    .size()\n",
    "    .reset_index(name=\"Count\")\n",
    "    .sort_values(by=[\"Job Location\", \"Count\"], ascending=[True, False]))\n",
    "print(skills_by_location_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8d610fc4-25a5-4113-83c2-f0b34162d434",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Job Type\n",
       "Onsite    18773\n",
       "Hybrid        7\n",
       "Remote        4\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count occurrences of top 10 job locations\n",
    "jobtypes = filtered_top_skills_df[\"Job Type\"].value_counts().head()\n",
    "jobtypes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a2664bcd-9e44-40fe-b45e-f6d15faaa69b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6696f8c389834832836804b9351d3232",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "SelectMultiple(description='Job Skills', index=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9), layout=Layout(height='200px', wâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34c60b27b35f450db18b76bd501c44a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Convert the default selection to a tuple\n",
    "skills_filter = widgets.SelectMultiple(\n",
    "    options=list(skills_by_location_count[\"Job Skills\"].unique()),  \n",
    "    value=tuple(skills_by_location_count[\"Job Skills\"].unique()[:10]),\n",
    "    description='Job Skills',\n",
    "    layout=widgets.Layout(width='50%', height='200px'),\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "# Function to update the bar chart\n",
    "def update_bar_chart(selected_skills):\n",
    "    # Ensure selected_skills is a list\n",
    "    if isinstance(selected_skills, str):\n",
    "        selected_skills = [selected_skills]\n",
    "        \n",
    "    # Filter the data based on selected job skills\n",
    "    filtered_data = skills_by_location_count[\n",
    "        skills_by_location_count[\"Job Skills\"].isin(selected_skills)\n",
    "    ]\n",
    "\n",
    "    # Create the bar chart\n",
    "    fig = px.bar(\n",
    "        filtered_data,\n",
    "        x=\"Job Skills\",\n",
    "        y=\"Count\",\n",
    "        color=\"Job Location\",\n",
    "        title=\"Top 10 Job Skills within the Top 10 Job Locations\",\n",
    "        labels={\"Count\": \"Number of Occurrences\", \"Job Skills\": \"Skills\"},\n",
    "        barmode=\"group\"\n",
    "    )\n",
    "    \n",
    "    fig.show()\n",
    "\n",
    "# Use widgets.interactive_output to link the function and widget\n",
    "interactive_bar_chart = widgets.interactive_output(update_bar_chart, {\"selected_skills\": skills_filter})\n",
    "\n",
    "# Display the filter widget and the bar chart\n",
    "display(skills_filter, interactive_bar_chart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0ec6eadd-9750-44e6-adcb-b7809563967f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f68979ca66c3489b8a453896bad397bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "SelectMultiple(description='Job Skills', index=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9), layout=Layout(height='150px', wâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbe24165f84340a2a1f06140b1b1f89a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create skills filter\n",
    "skills_filter = widgets.SelectMultiple(\n",
    "    options=list(skills_by_location_count[\"Job Skills\"].unique()), # Flexible list for dropdown options\n",
    "    value=tuple(skills_by_location_count[\"Job Skills\"].unique()[:10]), # Set tuple for default selection\n",
    "    description='Job Skills',\n",
    "    layout=widgets.Layout(width='50%', height='150px'),\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "# Function to update the sunburst chart with two filters\n",
    "def update_chart(selected_skills):\n",
    "    \n",
    "    # Ensure the selection is a list, even if only one selection made\n",
    "    if isinstance(selected_skills, str):\n",
    "        selected_skills = [selected_skills]\n",
    "        \n",
    "    # Filter the data based on selected job skills\n",
    "    filtered_data = skills_by_location_count[\n",
    "        skills_by_location_count[\"Job Skills\"].isin(selected_skills)\n",
    "    ]\n",
    "\n",
    "    # Create sunburst chart\n",
    "    fig = px.sunburst(\n",
    "        filtered_data,\n",
    "        path=[\"Job Skills\", \"Job Location\"],\n",
    "        values=\"Count\",\n",
    "        title=\"Top Job Skills with Top Job Locations\",\n",
    "        color=\"Job Skills\",\n",
    "        width=1000,\n",
    "        height=800\n",
    "    )\n",
    "    \n",
    "    # Set the text orientation to a consistent angle\n",
    "    fig.update_traces(insidetextorientation=\"radial\")\n",
    "    fig.show()\n",
    "\n",
    "# Use widgets.interactive to link the function and widget\n",
    "interactive_chart = widgets.interactive_output(update_chart, {\"selected_skills\": skills_filter})\n",
    "\n",
    "# Display the interactive widget and output\n",
    "display(skills_filter, interactive_chart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0456530-9e1a-4d33-948e-096dc0cd2b23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
