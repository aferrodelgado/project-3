{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eaf8ecaa-ff98-4150-a071-f099db9ff020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/asaniczka/data-science-job-postings-and-skills\n",
      "License(s): ODC Attribution License (ODC-By)\n",
      "Downloading data-science-job-postings-and-skills.zip to /Users/amandadelgado/Desktop/project-3\n",
      " 88%|█████████████████████████████████▎    | 17.0M/19.4M [00:00<00:00, 34.6MB/s]\n",
      "100%|██████████████████████████████████████| 19.4M/19.4M [00:00<00:00, 25.8MB/s]\n"
     ]
    }
   ],
   "source": [
    "#Dependencies and Setup\n",
    "from api_keys import KAGGLE_USERNAME, KAGGLE_KEY\n",
    "import os\n",
    "import json\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "from geopy.geocoders import Nominatim\n",
    "\n",
    "#Set environment variables for Kaggle API\n",
    "os.environ[\"KAGGLE_USERNAME\"] = KAGGLE_USERNAME\n",
    "os.environ[\"KAGGLE_KEY\"] = KAGGLE_KEY\n",
    "\n",
    "#Download Kaggle datasets\n",
    "!kaggle datasets download -d asaniczka/data-science-job-postings-and-skills --unzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81617fa4-4bdb-4cae-a5a2-7dee83fb1e17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_link</th>\n",
       "      <th>last_processed_time</th>\n",
       "      <th>last_status</th>\n",
       "      <th>got_summary</th>\n",
       "      <th>got_ner</th>\n",
       "      <th>is_being_worked</th>\n",
       "      <th>job_title</th>\n",
       "      <th>company</th>\n",
       "      <th>job_location</th>\n",
       "      <th>first_seen</th>\n",
       "      <th>search_city</th>\n",
       "      <th>search_country</th>\n",
       "      <th>search_position</th>\n",
       "      <th>job_level</th>\n",
       "      <th>job_type</th>\n",
       "      <th>job_skills</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.linkedin.com/jobs/view/senior-mach...</td>\n",
       "      <td>2024-01-21 08:08:48.031964+00</td>\n",
       "      <td>Finished NER</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>Senior Machine Learning Engineer</td>\n",
       "      <td>Jobs for Humanity</td>\n",
       "      <td>New Haven, CT</td>\n",
       "      <td>2024-01-14</td>\n",
       "      <td>East Haven</td>\n",
       "      <td>United States</td>\n",
       "      <td>Agricultural-Research Engineer</td>\n",
       "      <td>Mid senior</td>\n",
       "      <td>Onsite</td>\n",
       "      <td>Machine Learning, Programming, Python, Scala, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.linkedin.com/jobs/view/principal-s...</td>\n",
       "      <td>2024-01-20 04:02:12.331406+00</td>\n",
       "      <td>Finished NER</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>Principal Software Engineer, ML Accelerators</td>\n",
       "      <td>Aurora</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>2024-01-14</td>\n",
       "      <td>El Cerrito</td>\n",
       "      <td>United States</td>\n",
       "      <td>Set-Key Driver</td>\n",
       "      <td>Mid senior</td>\n",
       "      <td>Onsite</td>\n",
       "      <td>C++, Python, PyTorch, TensorFlow, MXNet, CUDA,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.linkedin.com/jobs/view/senior-etl-...</td>\n",
       "      <td>2024-01-21 08:08:31.941595+00</td>\n",
       "      <td>Finished NER</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>Senior ETL Data Warehouse Specialist</td>\n",
       "      <td>Adame Services LLC</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>2024-01-14</td>\n",
       "      <td>Middletown</td>\n",
       "      <td>United States</td>\n",
       "      <td>Technical Support Specialist</td>\n",
       "      <td>Associate</td>\n",
       "      <td>Onsite</td>\n",
       "      <td>ETL, Data Integration, Data Transformation, Da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.linkedin.com/jobs/view/senior-data...</td>\n",
       "      <td>2024-01-20 15:30:55.796572+00</td>\n",
       "      <td>Finished NER</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>Senior Data Warehouse Developer / Architect</td>\n",
       "      <td>Morph Enterprise</td>\n",
       "      <td>Harrisburg, PA</td>\n",
       "      <td>2024-01-12</td>\n",
       "      <td>Lebanon</td>\n",
       "      <td>United States</td>\n",
       "      <td>Architect</td>\n",
       "      <td>Mid senior</td>\n",
       "      <td>Onsite</td>\n",
       "      <td>Data Lakes, Data Bricks, Azure Data Factory Pi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.linkedin.com/jobs/view/lead-data-e...</td>\n",
       "      <td>2024-01-21 08:08:58.312124+00</td>\n",
       "      <td>Finished NER</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>Lead Data Engineer</td>\n",
       "      <td>Dice</td>\n",
       "      <td>Plano, TX</td>\n",
       "      <td>2024-01-14</td>\n",
       "      <td>McKinney</td>\n",
       "      <td>United States</td>\n",
       "      <td>Maintenance Data Analyst</td>\n",
       "      <td>Mid senior</td>\n",
       "      <td>Onsite</td>\n",
       "      <td>Java, Scala, Python, RDBMS, NoSQL, Redshift, S...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            job_link  \\\n",
       "0  https://www.linkedin.com/jobs/view/senior-mach...   \n",
       "1  https://www.linkedin.com/jobs/view/principal-s...   \n",
       "2  https://www.linkedin.com/jobs/view/senior-etl-...   \n",
       "3  https://www.linkedin.com/jobs/view/senior-data...   \n",
       "4  https://www.linkedin.com/jobs/view/lead-data-e...   \n",
       "\n",
       "             last_processed_time   last_status got_summary got_ner  \\\n",
       "0  2024-01-21 08:08:48.031964+00  Finished NER           t       t   \n",
       "1  2024-01-20 04:02:12.331406+00  Finished NER           t       t   \n",
       "2  2024-01-21 08:08:31.941595+00  Finished NER           t       t   \n",
       "3  2024-01-20 15:30:55.796572+00  Finished NER           t       t   \n",
       "4  2024-01-21 08:08:58.312124+00  Finished NER           t       t   \n",
       "\n",
       "  is_being_worked                                     job_title  \\\n",
       "0               f              Senior Machine Learning Engineer   \n",
       "1               f  Principal Software Engineer, ML Accelerators   \n",
       "2               f          Senior ETL Data Warehouse Specialist   \n",
       "3               f   Senior Data Warehouse Developer / Architect   \n",
       "4               f                            Lead Data Engineer   \n",
       "\n",
       "              company       job_location  first_seen search_city  \\\n",
       "0   Jobs for Humanity      New Haven, CT  2024-01-14  East Haven   \n",
       "1              Aurora  San Francisco, CA  2024-01-14  El Cerrito   \n",
       "2  Adame Services LLC       New York, NY  2024-01-14  Middletown   \n",
       "3    Morph Enterprise     Harrisburg, PA  2024-01-12     Lebanon   \n",
       "4                Dice          Plano, TX  2024-01-14    McKinney   \n",
       "\n",
       "  search_country                 search_position   job_level job_type  \\\n",
       "0  United States  Agricultural-Research Engineer  Mid senior   Onsite   \n",
       "1  United States                  Set-Key Driver  Mid senior   Onsite   \n",
       "2  United States    Technical Support Specialist   Associate   Onsite   \n",
       "3  United States                       Architect  Mid senior   Onsite   \n",
       "4  United States        Maintenance Data Analyst  Mid senior   Onsite   \n",
       "\n",
       "                                          job_skills  \n",
       "0  Machine Learning, Programming, Python, Scala, ...  \n",
       "1  C++, Python, PyTorch, TensorFlow, MXNet, CUDA,...  \n",
       "2  ETL, Data Integration, Data Transformation, Da...  \n",
       "3  Data Lakes, Data Bricks, Azure Data Factory Pi...  \n",
       "4  Java, Scala, Python, RDBMS, NoSQL, Redshift, S...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load CSV files\n",
    "job_skills_df = pd.read_csv(\"job_skills.csv\")\n",
    "job_postings_df = pd.read_csv(\"job_postings.csv\")\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Merge job_postings and job_skills dataframes on the 'job_link' column\n",
    "job_skills_postings_merged_df = pd.merge(job_postings_df, job_skills_df, on='job_link', how='inner')\n",
    "job_skills_postings_merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d643de31-c9dc-4c1f-9043-cb0979e9d29e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>company</th>\n",
       "      <th>job_location</th>\n",
       "      <th>first_seen</th>\n",
       "      <th>search_country</th>\n",
       "      <th>search_position</th>\n",
       "      <th>job_level</th>\n",
       "      <th>job_type</th>\n",
       "      <th>job_skills</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senior Machine Learning Engineer</td>\n",
       "      <td>Jobs for Humanity</td>\n",
       "      <td>New Haven, CT</td>\n",
       "      <td>2024-01-14</td>\n",
       "      <td>United States</td>\n",
       "      <td>Agricultural-Research Engineer</td>\n",
       "      <td>Mid senior</td>\n",
       "      <td>Onsite</td>\n",
       "      <td>Machine Learning, Programming, Python, Scala, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Principal Software Engineer, ML Accelerators</td>\n",
       "      <td>Aurora</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>2024-01-14</td>\n",
       "      <td>United States</td>\n",
       "      <td>Set-Key Driver</td>\n",
       "      <td>Mid senior</td>\n",
       "      <td>Onsite</td>\n",
       "      <td>C++, Python, PyTorch, TensorFlow, MXNet, CUDA,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior ETL Data Warehouse Specialist</td>\n",
       "      <td>Adame Services LLC</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>2024-01-14</td>\n",
       "      <td>United States</td>\n",
       "      <td>Technical Support Specialist</td>\n",
       "      <td>Associate</td>\n",
       "      <td>Onsite</td>\n",
       "      <td>ETL, Data Integration, Data Transformation, Da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Senior Data Warehouse Developer / Architect</td>\n",
       "      <td>Morph Enterprise</td>\n",
       "      <td>Harrisburg, PA</td>\n",
       "      <td>2024-01-12</td>\n",
       "      <td>United States</td>\n",
       "      <td>Architect</td>\n",
       "      <td>Mid senior</td>\n",
       "      <td>Onsite</td>\n",
       "      <td>Data Lakes, Data Bricks, Azure Data Factory Pi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lead Data Engineer</td>\n",
       "      <td>Dice</td>\n",
       "      <td>Plano, TX</td>\n",
       "      <td>2024-01-14</td>\n",
       "      <td>United States</td>\n",
       "      <td>Maintenance Data Analyst</td>\n",
       "      <td>Mid senior</td>\n",
       "      <td>Onsite</td>\n",
       "      <td>Java, Scala, Python, RDBMS, NoSQL, Redshift, S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12212</th>\n",
       "      <td>Data Reporting Manager, FOOTBALL ASSOCIATION</td>\n",
       "      <td>Guardian Jobs</td>\n",
       "      <td>Wembley, England, United Kingdom</td>\n",
       "      <td>2024-01-16</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Manager Forms Analysis</td>\n",
       "      <td>Mid senior</td>\n",
       "      <td>Onsite</td>\n",
       "      <td>Dashboard development, Reporting, Power BI, SQ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12213</th>\n",
       "      <td>Corporate AML Alert Investigation Specialist</td>\n",
       "      <td>Glacier Bancorp, Inc.</td>\n",
       "      <td>Kalispell, MT</td>\n",
       "      <td>2024-01-14</td>\n",
       "      <td>United States</td>\n",
       "      <td>Teller</td>\n",
       "      <td>Mid senior</td>\n",
       "      <td>Onsite</td>\n",
       "      <td>Investigation, Antimoney laundering, Fraud, Ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12214</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Highnote</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>2024-01-16</td>\n",
       "      <td>United States</td>\n",
       "      <td>Mathematician</td>\n",
       "      <td>Mid senior</td>\n",
       "      <td>Onsite</td>\n",
       "      <td>Data Science, Quantitative Modeling, SQL, Data...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12215</th>\n",
       "      <td>Senior Data Engineer</td>\n",
       "      <td>CompSource Mutual Insurance Company</td>\n",
       "      <td>Oklahoma City, OK</td>\n",
       "      <td>2024-01-16</td>\n",
       "      <td>United States</td>\n",
       "      <td>Protection Engineer</td>\n",
       "      <td>Mid senior</td>\n",
       "      <td>Onsite</td>\n",
       "      <td>Data Engineering, Data Quality, SQL, Python, T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12216</th>\n",
       "      <td>Medical Technologist, MLS or MLT</td>\n",
       "      <td>Community Health Systems</td>\n",
       "      <td>Mooresville, NC</td>\n",
       "      <td>2024-01-14</td>\n",
       "      <td>United States</td>\n",
       "      <td>Biologist</td>\n",
       "      <td>Mid senior</td>\n",
       "      <td>Onsite</td>\n",
       "      <td>Medical Technology, MLS, Microbiology, Clinica...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12217 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          job_title  \\\n",
       "0                  Senior Machine Learning Engineer   \n",
       "1      Principal Software Engineer, ML Accelerators   \n",
       "2              Senior ETL Data Warehouse Specialist   \n",
       "3       Senior Data Warehouse Developer / Architect   \n",
       "4                                Lead Data Engineer   \n",
       "...                                             ...   \n",
       "12212  Data Reporting Manager, FOOTBALL ASSOCIATION   \n",
       "12213  Corporate AML Alert Investigation Specialist   \n",
       "12214                         Senior Data Scientist   \n",
       "12215                          Senior Data Engineer   \n",
       "12216              Medical Technologist, MLS or MLT   \n",
       "\n",
       "                                   company                      job_location  \\\n",
       "0                        Jobs for Humanity                     New Haven, CT   \n",
       "1                                   Aurora                 San Francisco, CA   \n",
       "2                       Adame Services LLC                      New York, NY   \n",
       "3                         Morph Enterprise                    Harrisburg, PA   \n",
       "4                                     Dice                         Plano, TX   \n",
       "...                                    ...                               ...   \n",
       "12212                        Guardian Jobs  Wembley, England, United Kingdom   \n",
       "12213                Glacier Bancorp, Inc.                     Kalispell, MT   \n",
       "12214                             Highnote                 San Francisco, CA   \n",
       "12215  CompSource Mutual Insurance Company                 Oklahoma City, OK   \n",
       "12216             Community Health Systems                   Mooresville, NC   \n",
       "\n",
       "       first_seen  search_country                 search_position   job_level  \\\n",
       "0      2024-01-14   United States  Agricultural-Research Engineer  Mid senior   \n",
       "1      2024-01-14   United States                  Set-Key Driver  Mid senior   \n",
       "2      2024-01-14   United States    Technical Support Specialist   Associate   \n",
       "3      2024-01-12   United States                       Architect  Mid senior   \n",
       "4      2024-01-14   United States        Maintenance Data Analyst  Mid senior   \n",
       "...           ...             ...                             ...         ...   \n",
       "12212  2024-01-16  United Kingdom          Manager Forms Analysis  Mid senior   \n",
       "12213  2024-01-14   United States                          Teller  Mid senior   \n",
       "12214  2024-01-16   United States                   Mathematician  Mid senior   \n",
       "12215  2024-01-16   United States             Protection Engineer  Mid senior   \n",
       "12216  2024-01-14   United States                       Biologist  Mid senior   \n",
       "\n",
       "      job_type                                         job_skills  \n",
       "0       Onsite  Machine Learning, Programming, Python, Scala, ...  \n",
       "1       Onsite  C++, Python, PyTorch, TensorFlow, MXNet, CUDA,...  \n",
       "2       Onsite  ETL, Data Integration, Data Transformation, Da...  \n",
       "3       Onsite  Data Lakes, Data Bricks, Azure Data Factory Pi...  \n",
       "4       Onsite  Java, Scala, Python, RDBMS, NoSQL, Redshift, S...  \n",
       "...        ...                                                ...  \n",
       "12212   Onsite  Dashboard development, Reporting, Power BI, SQ...  \n",
       "12213   Onsite  Investigation, Antimoney laundering, Fraud, Ba...  \n",
       "12214   Onsite  Data Science, Quantitative Modeling, SQL, Data...  \n",
       "12215   Onsite  Data Engineering, Data Quality, SQL, Python, T...  \n",
       "12216   Onsite  Medical Technology, MLS, Microbiology, Clinica...  \n",
       "\n",
       "[12217 rows x 9 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Remove unwanted columns\n",
    "job_skills_postings_df = job_skills_postings_merged_df[['job_title',\n",
    "                                                        'company',\n",
    "                                                        'job_location',\n",
    "                                                        'first_seen',\n",
    "                                                        'search_country',\n",
    "                                                        'search_position',\n",
    "                                                        'job_level',\n",
    "                                                        'job_type',\n",
    "                                                        'job_skills'\n",
    "                                                       ]]\n",
    "job_skills_postings_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28091437-2ccc-4ff6-ace2-930a2dca78c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "job_title          12217\n",
       "company            12217\n",
       "job_location       12216\n",
       "first_seen         12217\n",
       "search_country     12217\n",
       "search_position    12217\n",
       "job_level          12217\n",
       "job_type           12217\n",
       "job_skills         12212\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_skills_postings_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "452ef96b-4052-400e-ac9a-6bc2eb8f87f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Job Location</th>\n",
       "      <th>Job Location City</th>\n",
       "      <th>Job Location State</th>\n",
       "      <th>Job Posting Seen</th>\n",
       "      <th>Country</th>\n",
       "      <th>Position</th>\n",
       "      <th>Job Level</th>\n",
       "      <th>Job Type</th>\n",
       "      <th>Job Skills</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senior Machine Learning Engineer</td>\n",
       "      <td>Jobs for Humanity</td>\n",
       "      <td>New Haven, CT</td>\n",
       "      <td>New Haven</td>\n",
       "      <td>CT</td>\n",
       "      <td>2024-01-14</td>\n",
       "      <td>United States</td>\n",
       "      <td>Agricultural-Research Engineer</td>\n",
       "      <td>Mid senior</td>\n",
       "      <td>Onsite</td>\n",
       "      <td>Machine Learning, Programming, Python, Scala, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Principal Software Engineer, ML Accelerators</td>\n",
       "      <td>Aurora</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>CA</td>\n",
       "      <td>2024-01-14</td>\n",
       "      <td>United States</td>\n",
       "      <td>Set-Key Driver</td>\n",
       "      <td>Mid senior</td>\n",
       "      <td>Onsite</td>\n",
       "      <td>C++, Python, PyTorch, TensorFlow, MXNet, CUDA,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior ETL Data Warehouse Specialist</td>\n",
       "      <td>Adame Services LLC</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>2024-01-14</td>\n",
       "      <td>United States</td>\n",
       "      <td>Technical Support Specialist</td>\n",
       "      <td>Associate</td>\n",
       "      <td>Onsite</td>\n",
       "      <td>ETL, Data Integration, Data Transformation, Da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Senior Data Warehouse Developer / Architect</td>\n",
       "      <td>Morph Enterprise</td>\n",
       "      <td>Harrisburg, PA</td>\n",
       "      <td>Harrisburg</td>\n",
       "      <td>PA</td>\n",
       "      <td>2024-01-12</td>\n",
       "      <td>United States</td>\n",
       "      <td>Architect</td>\n",
       "      <td>Mid senior</td>\n",
       "      <td>Onsite</td>\n",
       "      <td>Data Lakes, Data Bricks, Azure Data Factory Pi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lead Data Engineer</td>\n",
       "      <td>Dice</td>\n",
       "      <td>Plano, TX</td>\n",
       "      <td>Plano</td>\n",
       "      <td>TX</td>\n",
       "      <td>2024-01-14</td>\n",
       "      <td>United States</td>\n",
       "      <td>Maintenance Data Analyst</td>\n",
       "      <td>Mid senior</td>\n",
       "      <td>Onsite</td>\n",
       "      <td>Java, Scala, Python, RDBMS, NoSQL, Redshift, S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12212</th>\n",
       "      <td>Data Reporting Manager, FOOTBALL ASSOCIATION</td>\n",
       "      <td>Guardian Jobs</td>\n",
       "      <td>Wembley, England, United Kingdom</td>\n",
       "      <td>Wembley</td>\n",
       "      <td>England, United Kingdom</td>\n",
       "      <td>2024-01-16</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Manager Forms Analysis</td>\n",
       "      <td>Mid senior</td>\n",
       "      <td>Onsite</td>\n",
       "      <td>Dashboard development, Reporting, Power BI, SQ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12213</th>\n",
       "      <td>Corporate AML Alert Investigation Specialist</td>\n",
       "      <td>Glacier Bancorp, Inc.</td>\n",
       "      <td>Kalispell, MT</td>\n",
       "      <td>Kalispell</td>\n",
       "      <td>MT</td>\n",
       "      <td>2024-01-14</td>\n",
       "      <td>United States</td>\n",
       "      <td>Teller</td>\n",
       "      <td>Mid senior</td>\n",
       "      <td>Onsite</td>\n",
       "      <td>Investigation, Antimoney laundering, Fraud, Ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12214</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Highnote</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>CA</td>\n",
       "      <td>2024-01-16</td>\n",
       "      <td>United States</td>\n",
       "      <td>Mathematician</td>\n",
       "      <td>Mid senior</td>\n",
       "      <td>Onsite</td>\n",
       "      <td>Data Science, Quantitative Modeling, SQL, Data...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12215</th>\n",
       "      <td>Senior Data Engineer</td>\n",
       "      <td>CompSource Mutual Insurance Company</td>\n",
       "      <td>Oklahoma City, OK</td>\n",
       "      <td>Oklahoma City</td>\n",
       "      <td>OK</td>\n",
       "      <td>2024-01-16</td>\n",
       "      <td>United States</td>\n",
       "      <td>Protection Engineer</td>\n",
       "      <td>Mid senior</td>\n",
       "      <td>Onsite</td>\n",
       "      <td>Data Engineering, Data Quality, SQL, Python, T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12216</th>\n",
       "      <td>Medical Technologist, MLS or MLT</td>\n",
       "      <td>Community Health Systems</td>\n",
       "      <td>Mooresville, NC</td>\n",
       "      <td>Mooresville</td>\n",
       "      <td>NC</td>\n",
       "      <td>2024-01-14</td>\n",
       "      <td>United States</td>\n",
       "      <td>Biologist</td>\n",
       "      <td>Mid senior</td>\n",
       "      <td>Onsite</td>\n",
       "      <td>Medical Technology, MLS, Microbiology, Clinica...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12217 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Job Title  \\\n",
       "0                  Senior Machine Learning Engineer   \n",
       "1      Principal Software Engineer, ML Accelerators   \n",
       "2              Senior ETL Data Warehouse Specialist   \n",
       "3       Senior Data Warehouse Developer / Architect   \n",
       "4                                Lead Data Engineer   \n",
       "...                                             ...   \n",
       "12212  Data Reporting Manager, FOOTBALL ASSOCIATION   \n",
       "12213  Corporate AML Alert Investigation Specialist   \n",
       "12214                         Senior Data Scientist   \n",
       "12215                          Senior Data Engineer   \n",
       "12216              Medical Technologist, MLS or MLT   \n",
       "\n",
       "                                   Company                      Job Location  \\\n",
       "0                        Jobs for Humanity                     New Haven, CT   \n",
       "1                                   Aurora                 San Francisco, CA   \n",
       "2                       Adame Services LLC                      New York, NY   \n",
       "3                         Morph Enterprise                    Harrisburg, PA   \n",
       "4                                     Dice                         Plano, TX   \n",
       "...                                    ...                               ...   \n",
       "12212                        Guardian Jobs  Wembley, England, United Kingdom   \n",
       "12213                Glacier Bancorp, Inc.                     Kalispell, MT   \n",
       "12214                             Highnote                 San Francisco, CA   \n",
       "12215  CompSource Mutual Insurance Company                 Oklahoma City, OK   \n",
       "12216             Community Health Systems                   Mooresville, NC   \n",
       "\n",
       "      Job Location City       Job Location State Job Posting Seen  \\\n",
       "0             New Haven                       CT       2024-01-14   \n",
       "1         San Francisco                       CA       2024-01-14   \n",
       "2              New York                       NY       2024-01-14   \n",
       "3            Harrisburg                       PA       2024-01-12   \n",
       "4                 Plano                       TX       2024-01-14   \n",
       "...                 ...                      ...              ...   \n",
       "12212           Wembley  England, United Kingdom       2024-01-16   \n",
       "12213         Kalispell                       MT       2024-01-14   \n",
       "12214     San Francisco                       CA       2024-01-16   \n",
       "12215     Oklahoma City                       OK       2024-01-16   \n",
       "12216       Mooresville                       NC       2024-01-14   \n",
       "\n",
       "              Country                        Position   Job Level Job Type  \\\n",
       "0       United States  Agricultural-Research Engineer  Mid senior   Onsite   \n",
       "1       United States                  Set-Key Driver  Mid senior   Onsite   \n",
       "2       United States    Technical Support Specialist   Associate   Onsite   \n",
       "3       United States                       Architect  Mid senior   Onsite   \n",
       "4       United States        Maintenance Data Analyst  Mid senior   Onsite   \n",
       "...               ...                             ...         ...      ...   \n",
       "12212  United Kingdom          Manager Forms Analysis  Mid senior   Onsite   \n",
       "12213   United States                          Teller  Mid senior   Onsite   \n",
       "12214   United States                   Mathematician  Mid senior   Onsite   \n",
       "12215   United States             Protection Engineer  Mid senior   Onsite   \n",
       "12216   United States                       Biologist  Mid senior   Onsite   \n",
       "\n",
       "                                              Job Skills  \n",
       "0      Machine Learning, Programming, Python, Scala, ...  \n",
       "1      C++, Python, PyTorch, TensorFlow, MXNet, CUDA,...  \n",
       "2      ETL, Data Integration, Data Transformation, Da...  \n",
       "3      Data Lakes, Data Bricks, Azure Data Factory Pi...  \n",
       "4      Java, Scala, Python, RDBMS, NoSQL, Redshift, S...  \n",
       "...                                                  ...  \n",
       "12212  Dashboard development, Reporting, Power BI, SQ...  \n",
       "12213  Investigation, Antimoney laundering, Fraud, Ba...  \n",
       "12214  Data Science, Quantitative Modeling, SQL, Data...  \n",
       "12215  Data Engineering, Data Quality, SQL, Python, T...  \n",
       "12216  Medical Technology, MLS, Microbiology, Clinica...  \n",
       "\n",
       "[12217 rows x 11 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Rename columns\n",
    "job_skills_postings_df = job_skills_postings_df.rename(columns={\"job_title\": \"Job Title\",\n",
    "                                                        \"company\": \"Company\",\n",
    "                                                        \"job_location\": \"Job Location\",\n",
    "                                                        \"first_seen\": \"Job Posting Seen\",\n",
    "                                                        \"search_country\": \"Country\",\n",
    "                                                        \"search_position\": \"Position\",\n",
    "                                                        \"job_level\": \"Job Level\",\n",
    "                                                        \"job_type\": \"Job Type\",\n",
    "                                                        \"job_skills\": \"Job Skills\"\n",
    "                                                               })\n",
    "\n",
    "# Ensure all entries in 'Job Location' are strings for consistent splitting\n",
    "job_skills_postings_df['Job Location'] = job_skills_postings_df['Job Location'].astype(str)\n",
    "\n",
    "# Split 'Job Location' into 'Job Location City' and 'Job Location State'\n",
    "split_location = job_skills_postings_df['Job Location'].str.split(', ', n=1, expand=True)\n",
    "job_skills_postings_df['Job Location City'] = split_location[0]\n",
    "job_skills_postings_df['Job Location State'] = split_location[1]\n",
    "\n",
    "# Reorder columns to place 'Job Location City' and 'Job Location State' after 'Job Location'\n",
    "columns = list(job_skills_postings_df.columns)\n",
    "new_order = columns[:3] + ['Job Location City', 'Job Location State'] + columns[3:-2]\n",
    "job_skills_postings_df = job_skills_postings_df[new_order]\n",
    "\n",
    "job_skills_postings_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f162ebef-9877-4ccc-9f3b-b200b46dfa3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object\n"
     ]
    }
   ],
   "source": [
    "print(job_skills_postings_df[\"Job Posting Seen\"].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62334419-ab8a-420c-827e-3a1a0ab2c0f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "# Convert 'Job Posting Seen' to datetime format\n",
    "job_skills_postings_df[\"Job Posting Seen\"] = pd.to_datetime(job_skills_postings_df[\"Job Posting Seen\"])\n",
    "print(job_skills_postings_df[\"Job Posting Seen\"].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c23d1c89-0d58-4f5f-ae7c-c46276e5b318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country\n",
      "United States     10291\n",
      "United Kingdom      995\n",
      "Canada              630\n",
      "Australia           301\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "country_counts = job_skills_postings_df['Country'].value_counts()\n",
    "print(country_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b59eca9c-23b7-4719-ad66-a32c50d00c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country\n",
      "United States    10291\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Filter the DataFrame for rows where Country is 'United States'\n",
    "us_job_skills_df = job_skills_postings_df[job_skills_postings_df[\"Country\"] == \"United States\"]\n",
    "us_job_skills_counts = us_job_skills_df['Country'].value_counts()\n",
    "print(us_job_skills_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "85e4173c-81d1-4edc-81d8-9eb5428afef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    Machine Learning, Programming, Python, Scala, ...\n",
      "1    C++, Python, PyTorch, TensorFlow, MXNet, CUDA,...\n",
      "2    ETL, Data Integration, Data Transformation, Da...\n",
      "3    Data Lakes, Data Bricks, Azure Data Factory Pi...\n",
      "4    Java, Scala, Python, RDBMS, NoSQL, Redshift, S...\n",
      "Name: Job Skills, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Display the first few rows of the 'Job Skills' column to inspect the structure\n",
    "print(us_job_skills_df[\"Job Skills\"].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "33e3585e-6029-4d23-971e-161d8964c814",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split 'Job Skills' by comma in the filtered DataFrame\n",
    "us_job_skills_df.loc[:, \"Job Skills\"] = us_job_skills_df[\"Job Skills\"].str.split(\",\")\n",
    "\n",
    "# Explode to create a new row for each skill\n",
    "skills_df = us_job_skills_df.explode(\"Job Skills\")\n",
    "\n",
    "# Strip whitespace around each skill\n",
    "skills_df[\"Job Skills\"] = skills_df[\"Job Skills\"].str.strip()\n",
    "\n",
    "# Drop any empty strings that may remain\n",
    "skills_df = skills_df[skills_df[\"Job Skills\"] != \"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6f118294-242f-4f28-83a1-1f6cf42e9f90",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job Skills\n",
      "Python                4071\n",
      "SQL                   3855\n",
      "Communication         2013\n",
      "Data Analysis         1762\n",
      "Machine Learning      1694\n",
      "AWS                   1561\n",
      "Tableau               1394\n",
      "Java                  1281\n",
      "R                     1275\n",
      "Data Visualization    1261\n",
      "Spark                 1229\n",
      "Data Science          1098\n",
      "Data Engineering      1065\n",
      "Project Management    1023\n",
      "Teamwork               982\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Count occurrences of each skill and get the top 15\n",
    "top_skills = skills_df[\"Job Skills\"].value_counts().head(15)\n",
    "print(top_skills)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b27c315b-7387-43d2-b648-4cb48e4600e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Job Location</th>\n",
       "      <th>Job Location City</th>\n",
       "      <th>Job Location State</th>\n",
       "      <th>Job Posting Seen</th>\n",
       "      <th>Country</th>\n",
       "      <th>Position</th>\n",
       "      <th>Job Level</th>\n",
       "      <th>Job Type</th>\n",
       "      <th>Job Skills</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senior Machine Learning Engineer</td>\n",
       "      <td>Jobs for Humanity</td>\n",
       "      <td>New Haven, CT</td>\n",
       "      <td>New Haven</td>\n",
       "      <td>CT</td>\n",
       "      <td>2024-01-14</td>\n",
       "      <td>United States</td>\n",
       "      <td>Agricultural-Research Engineer</td>\n",
       "      <td>Mid senior</td>\n",
       "      <td>Onsite</td>\n",
       "      <td>Machine Learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senior Machine Learning Engineer</td>\n",
       "      <td>Jobs for Humanity</td>\n",
       "      <td>New Haven, CT</td>\n",
       "      <td>New Haven</td>\n",
       "      <td>CT</td>\n",
       "      <td>2024-01-14</td>\n",
       "      <td>United States</td>\n",
       "      <td>Agricultural-Research Engineer</td>\n",
       "      <td>Mid senior</td>\n",
       "      <td>Onsite</td>\n",
       "      <td>Programming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senior Machine Learning Engineer</td>\n",
       "      <td>Jobs for Humanity</td>\n",
       "      <td>New Haven, CT</td>\n",
       "      <td>New Haven</td>\n",
       "      <td>CT</td>\n",
       "      <td>2024-01-14</td>\n",
       "      <td>United States</td>\n",
       "      <td>Agricultural-Research Engineer</td>\n",
       "      <td>Mid senior</td>\n",
       "      <td>Onsite</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senior Machine Learning Engineer</td>\n",
       "      <td>Jobs for Humanity</td>\n",
       "      <td>New Haven, CT</td>\n",
       "      <td>New Haven</td>\n",
       "      <td>CT</td>\n",
       "      <td>2024-01-14</td>\n",
       "      <td>United States</td>\n",
       "      <td>Agricultural-Research Engineer</td>\n",
       "      <td>Mid senior</td>\n",
       "      <td>Onsite</td>\n",
       "      <td>Scala</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senior Machine Learning Engineer</td>\n",
       "      <td>Jobs for Humanity</td>\n",
       "      <td>New Haven, CT</td>\n",
       "      <td>New Haven</td>\n",
       "      <td>CT</td>\n",
       "      <td>2024-01-14</td>\n",
       "      <td>United States</td>\n",
       "      <td>Agricultural-Research Engineer</td>\n",
       "      <td>Mid senior</td>\n",
       "      <td>Onsite</td>\n",
       "      <td>Java</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12216</th>\n",
       "      <td>Medical Technologist, MLS or MLT</td>\n",
       "      <td>Community Health Systems</td>\n",
       "      <td>Mooresville, NC</td>\n",
       "      <td>Mooresville</td>\n",
       "      <td>NC</td>\n",
       "      <td>2024-01-14</td>\n",
       "      <td>United States</td>\n",
       "      <td>Biologist</td>\n",
       "      <td>Mid senior</td>\n",
       "      <td>Onsite</td>\n",
       "      <td>Graduation from Accredited MT/MLS Program</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12216</th>\n",
       "      <td>Medical Technologist, MLS or MLT</td>\n",
       "      <td>Community Health Systems</td>\n",
       "      <td>Mooresville, NC</td>\n",
       "      <td>Mooresville</td>\n",
       "      <td>NC</td>\n",
       "      <td>2024-01-14</td>\n",
       "      <td>United States</td>\n",
       "      <td>Biologist</td>\n",
       "      <td>Mid senior</td>\n",
       "      <td>Onsite</td>\n",
       "      <td>National Exam Passing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12216</th>\n",
       "      <td>Medical Technologist, MLS or MLT</td>\n",
       "      <td>Community Health Systems</td>\n",
       "      <td>Mooresville, NC</td>\n",
       "      <td>Mooresville</td>\n",
       "      <td>NC</td>\n",
       "      <td>2024-01-14</td>\n",
       "      <td>United States</td>\n",
       "      <td>Biologist</td>\n",
       "      <td>Mid senior</td>\n",
       "      <td>Onsite</td>\n",
       "      <td>Board of Registry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12216</th>\n",
       "      <td>Medical Technologist, MLS or MLT</td>\n",
       "      <td>Community Health Systems</td>\n",
       "      <td>Mooresville, NC</td>\n",
       "      <td>Mooresville</td>\n",
       "      <td>NC</td>\n",
       "      <td>2024-01-14</td>\n",
       "      <td>United States</td>\n",
       "      <td>Biologist</td>\n",
       "      <td>Mid senior</td>\n",
       "      <td>Onsite</td>\n",
       "      <td>American Society for Clinical Pathology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12216</th>\n",
       "      <td>Medical Technologist, MLS or MLT</td>\n",
       "      <td>Community Health Systems</td>\n",
       "      <td>Mooresville, NC</td>\n",
       "      <td>Mooresville</td>\n",
       "      <td>NC</td>\n",
       "      <td>2024-01-14</td>\n",
       "      <td>United States</td>\n",
       "      <td>Biologist</td>\n",
       "      <td>Mid senior</td>\n",
       "      <td>Onsite</td>\n",
       "      <td>Microbiology Experience</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>268335 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Job Title                   Company  \\\n",
       "0      Senior Machine Learning Engineer         Jobs for Humanity   \n",
       "0      Senior Machine Learning Engineer         Jobs for Humanity   \n",
       "0      Senior Machine Learning Engineer         Jobs for Humanity   \n",
       "0      Senior Machine Learning Engineer         Jobs for Humanity   \n",
       "0      Senior Machine Learning Engineer         Jobs for Humanity   \n",
       "...                                 ...                       ...   \n",
       "12216  Medical Technologist, MLS or MLT  Community Health Systems   \n",
       "12216  Medical Technologist, MLS or MLT  Community Health Systems   \n",
       "12216  Medical Technologist, MLS or MLT  Community Health Systems   \n",
       "12216  Medical Technologist, MLS or MLT  Community Health Systems   \n",
       "12216  Medical Technologist, MLS or MLT  Community Health Systems   \n",
       "\n",
       "          Job Location Job Location City Job Location State Job Posting Seen  \\\n",
       "0        New Haven, CT         New Haven                 CT       2024-01-14   \n",
       "0        New Haven, CT         New Haven                 CT       2024-01-14   \n",
       "0        New Haven, CT         New Haven                 CT       2024-01-14   \n",
       "0        New Haven, CT         New Haven                 CT       2024-01-14   \n",
       "0        New Haven, CT         New Haven                 CT       2024-01-14   \n",
       "...                ...               ...                ...              ...   \n",
       "12216  Mooresville, NC       Mooresville                 NC       2024-01-14   \n",
       "12216  Mooresville, NC       Mooresville                 NC       2024-01-14   \n",
       "12216  Mooresville, NC       Mooresville                 NC       2024-01-14   \n",
       "12216  Mooresville, NC       Mooresville                 NC       2024-01-14   \n",
       "12216  Mooresville, NC       Mooresville                 NC       2024-01-14   \n",
       "\n",
       "             Country                        Position   Job Level Job Type  \\\n",
       "0      United States  Agricultural-Research Engineer  Mid senior   Onsite   \n",
       "0      United States  Agricultural-Research Engineer  Mid senior   Onsite   \n",
       "0      United States  Agricultural-Research Engineer  Mid senior   Onsite   \n",
       "0      United States  Agricultural-Research Engineer  Mid senior   Onsite   \n",
       "0      United States  Agricultural-Research Engineer  Mid senior   Onsite   \n",
       "...              ...                             ...         ...      ...   \n",
       "12216  United States                       Biologist  Mid senior   Onsite   \n",
       "12216  United States                       Biologist  Mid senior   Onsite   \n",
       "12216  United States                       Biologist  Mid senior   Onsite   \n",
       "12216  United States                       Biologist  Mid senior   Onsite   \n",
       "12216  United States                       Biologist  Mid senior   Onsite   \n",
       "\n",
       "                                      Job Skills  \n",
       "0                               Machine Learning  \n",
       "0                                    Programming  \n",
       "0                                         Python  \n",
       "0                                          Scala  \n",
       "0                                           Java  \n",
       "...                                          ...  \n",
       "12216  Graduation from Accredited MT/MLS Program  \n",
       "12216                      National Exam Passing  \n",
       "12216                          Board of Registry  \n",
       "12216    American Society for Clinical Pathology  \n",
       "12216                    Microbiology Experience  \n",
       "\n",
       "[268335 rows x 11 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skills_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fdd34f35-80ce-4c26-9b90-656719486cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export data to csv\n",
    "skills_df.to_csv('us_job_skills.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d182662d-c4ae-4781-9ba5-66a80ecde48a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job Skills\n",
      "Python                4071\n",
      "SQL                   3855\n",
      "Communication         2013\n",
      "Data Analysis         1762\n",
      "Machine Learning      1694\n",
      "AWS                   1561\n",
      "Tableau               1394\n",
      "Java                  1281\n",
      "R                     1275\n",
      "Data Visualization    1261\n",
      "Spark                 1229\n",
      "Data Science          1098\n",
      "Data Engineering      1065\n",
      "Project Management    1023\n",
      "Teamwork               982\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Count occurrences of each skill and get the top 15\n",
    "top_skills = skills_df[\"Job Skills\"].value_counts().head(15)\n",
    "print(top_skills)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5bcb4bb4-f857-4bac-b9de-965867c805e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Job Location</th>\n",
       "      <th>Job Location City</th>\n",
       "      <th>Job Location State</th>\n",
       "      <th>Job Posting Seen</th>\n",
       "      <th>Country</th>\n",
       "      <th>Position</th>\n",
       "      <th>Job Level</th>\n",
       "      <th>Job Type</th>\n",
       "      <th>Job Skills</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senior Machine Learning Engineer</td>\n",
       "      <td>Jobs for Humanity</td>\n",
       "      <td>New Haven, CT</td>\n",
       "      <td>New Haven</td>\n",
       "      <td>CT</td>\n",
       "      <td>2024-01-14</td>\n",
       "      <td>United States</td>\n",
       "      <td>Agricultural-Research Engineer</td>\n",
       "      <td>Mid senior</td>\n",
       "      <td>Onsite</td>\n",
       "      <td>Machine Learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senior Machine Learning Engineer</td>\n",
       "      <td>Jobs for Humanity</td>\n",
       "      <td>New Haven, CT</td>\n",
       "      <td>New Haven</td>\n",
       "      <td>CT</td>\n",
       "      <td>2024-01-14</td>\n",
       "      <td>United States</td>\n",
       "      <td>Agricultural-Research Engineer</td>\n",
       "      <td>Mid senior</td>\n",
       "      <td>Onsite</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senior Machine Learning Engineer</td>\n",
       "      <td>Jobs for Humanity</td>\n",
       "      <td>New Haven, CT</td>\n",
       "      <td>New Haven</td>\n",
       "      <td>CT</td>\n",
       "      <td>2024-01-14</td>\n",
       "      <td>United States</td>\n",
       "      <td>Agricultural-Research Engineer</td>\n",
       "      <td>Mid senior</td>\n",
       "      <td>Onsite</td>\n",
       "      <td>Data Engineering</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senior Machine Learning Engineer</td>\n",
       "      <td>Jobs for Humanity</td>\n",
       "      <td>New Haven, CT</td>\n",
       "      <td>New Haven</td>\n",
       "      <td>CT</td>\n",
       "      <td>2024-01-14</td>\n",
       "      <td>United States</td>\n",
       "      <td>Agricultural-Research Engineer</td>\n",
       "      <td>Mid senior</td>\n",
       "      <td>Onsite</td>\n",
       "      <td>Data Visualization</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Principal Software Engineer, ML Accelerators</td>\n",
       "      <td>Aurora</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>CA</td>\n",
       "      <td>2024-01-14</td>\n",
       "      <td>United States</td>\n",
       "      <td>Set-Key Driver</td>\n",
       "      <td>Mid senior</td>\n",
       "      <td>Onsite</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Job Title            Company  \\\n",
       "0              Senior Machine Learning Engineer  Jobs for Humanity   \n",
       "0              Senior Machine Learning Engineer  Jobs for Humanity   \n",
       "0              Senior Machine Learning Engineer  Jobs for Humanity   \n",
       "0              Senior Machine Learning Engineer  Jobs for Humanity   \n",
       "1  Principal Software Engineer, ML Accelerators             Aurora   \n",
       "\n",
       "        Job Location Job Location City Job Location State Job Posting Seen  \\\n",
       "0      New Haven, CT         New Haven                 CT       2024-01-14   \n",
       "0      New Haven, CT         New Haven                 CT       2024-01-14   \n",
       "0      New Haven, CT         New Haven                 CT       2024-01-14   \n",
       "0      New Haven, CT         New Haven                 CT       2024-01-14   \n",
       "1  San Francisco, CA     San Francisco                 CA       2024-01-14   \n",
       "\n",
       "         Country                        Position   Job Level Job Type  \\\n",
       "0  United States  Agricultural-Research Engineer  Mid senior   Onsite   \n",
       "0  United States  Agricultural-Research Engineer  Mid senior   Onsite   \n",
       "0  United States  Agricultural-Research Engineer  Mid senior   Onsite   \n",
       "0  United States  Agricultural-Research Engineer  Mid senior   Onsite   \n",
       "1  United States                  Set-Key Driver  Mid senior   Onsite   \n",
       "\n",
       "           Job Skills  \n",
       "0    Machine Learning  \n",
       "0              Python  \n",
       "0    Data Engineering  \n",
       "0  Data Visualization  \n",
       "1              Python  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List of top job skills, filtering by top 10 hard skill\n",
    "top_skills = ['Python', 'SQL', 'Data Analysis', 'Machine Learning', 'Data Visualization', 'AWS', 'Project Management', 'Data Science', 'Data Engineering', 'Tableau']  # Replace with your actual skills\n",
    "\n",
    "# Filter the original DataFrame to include only rows with these specific job skills\n",
    "filtered_top_skills_df = skills_df[skills_df[\"Job Skills\"].isin(top_skills)]\n",
    "\n",
    "# Print the filtered DataFrame\n",
    "filtered_top_skills_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a4a8cc53-0a7a-4e81-8b4f-62e43b184f87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 18784\n"
     ]
    }
   ],
   "source": [
    "row_count = len(filtered_top_skills_df)\n",
    "print(f\"Number of rows: {row_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "58454e79-43e7-45d9-8b5f-54d5bc33fd6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job Skills\n",
      "Python                4071\n",
      "SQL                   3855\n",
      "Data Analysis         1762\n",
      "Machine Learning      1694\n",
      "AWS                   1561\n",
      "Tableau               1394\n",
      "Data Visualization    1261\n",
      "Data Science          1098\n",
      "Data Engineering      1065\n",
      "Project Management    1023\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Count occurrences of top 10 skills\n",
    "top10_skills = filtered_top_skills_df[\"Job Skills\"].value_counts()\n",
    "print(top10_skills)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6965eb64-4e44-45c7-87a8-2b721fe5c836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      Company  Job Skills\n",
      "1107        Jobs for Humanity        1756\n",
      "1710  Recruiting from Scratch         679\n",
      "633                      Dice         377\n",
      "486              ClickJobs.io         346\n",
      "412               Capital One         302\n",
      "...                       ...         ...\n",
      "916            Grocery Outlet           1\n",
      "2024   Tampa General Hospital           1\n",
      "454        Chatham University           1\n",
      "2026           Tarrant County           1\n",
      "958         Henry Ford Health           1\n",
      "\n",
      "[2437 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Group by 'Company' and aggregate the 'Job Skills'\n",
    "# Option 1: Count the number of occurrences for each company\n",
    "skills_by_company_count = filtered_top_skills_df.groupby('Company')['Job Skills'].count().reset_index()\n",
    "skills_by_company_count = skills_by_company_count.sort_values(by='Job Skills', ascending=False)\n",
    "\n",
    "# Print the DataFrame showing the number of top skills per company\n",
    "print(skills_by_company_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "71ed0fb9-9e71-4970-bbbc-9d081cce8dad",
   "metadata": {},
   "outputs": [
    {
     "ename": "GeocoderInsufficientPrivileges",
     "evalue": "Non-successful status code 403",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAdapterHTTPError\u001b[0m                          Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/geopy/geocoders/base.py:368\u001b[0m, in \u001b[0;36mGeocoder._call_geocoder\u001b[0;34m(self, url, callback, timeout, is_json, headers)\u001b[0m\n\u001b[1;32m    367\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_json:\n\u001b[0;32m--> 368\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madapter\u001b[38;5;241m.\u001b[39mget_json(url, timeout\u001b[38;5;241m=\u001b[39mtimeout, headers\u001b[38;5;241m=\u001b[39mreq_headers)\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/geopy/adapters.py:472\u001b[0m, in \u001b[0;36mRequestsAdapter.get_json\u001b[0;34m(self, url, timeout, headers)\u001b[0m\n\u001b[1;32m    471\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_json\u001b[39m(\u001b[38;5;28mself\u001b[39m, url, \u001b[38;5;241m*\u001b[39m, timeout, headers):\n\u001b[0;32m--> 472\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request(url, timeout\u001b[38;5;241m=\u001b[39mtimeout, headers\u001b[38;5;241m=\u001b[39mheaders)\n\u001b[1;32m    473\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/geopy/adapters.py:500\u001b[0m, in \u001b[0;36mRequestsAdapter._request\u001b[0;34m(self, url, timeout, headers)\u001b[0m\n\u001b[1;32m    499\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m resp\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m400\u001b[39m:\n\u001b[0;32m--> 500\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m AdapterHTTPError(\n\u001b[1;32m    501\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNon-successful status code \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m resp\u001b[38;5;241m.\u001b[39mstatus_code,\n\u001b[1;32m    502\u001b[0m             status_code\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mstatus_code,\n\u001b[1;32m    503\u001b[0m             headers\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[1;32m    504\u001b[0m             text\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mtext,\n\u001b[1;32m    505\u001b[0m         )\n\u001b[1;32m    507\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[0;31mAdapterHTTPError\u001b[0m: Non-successful status code 403",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mGeocoderInsufficientPrivileges\u001b[0m            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 14\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Apply the function to get latitude and longitude\u001b[39;00m\n\u001b[1;32m     13\u001b[0m filtered_top_skills_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLatitude\u001b[39m\u001b[38;5;124m'\u001b[39m], filtered_top_skills_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLongitude\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\n\u001b[0;32m---> 14\u001b[0m     \u001b[38;5;241m*\u001b[39mfiltered_top_skills_df\u001b[38;5;241m.\u001b[39mapply(\n\u001b[1;32m     15\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m row: get_coordinates(row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mJob Location City\u001b[39m\u001b[38;5;124m'\u001b[39m], row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mJob Location State\u001b[39m\u001b[38;5;124m'\u001b[39m]),\n\u001b[1;32m     16\u001b[0m         axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     17\u001b[0m     )\n\u001b[1;32m     18\u001b[0m )\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Drop rows where coordinates were not found\u001b[39;00m\n\u001b[1;32m     21\u001b[0m filtered_top_skills_df \u001b[38;5;241m=\u001b[39m filtered_top_skills_df\u001b[38;5;241m.\u001b[39mdropna(subset\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLatitude\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLongitude\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/frame.py:10374\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[0;34m(self, func, axis, raw, result_type, args, by_row, engine, engine_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m  10360\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[1;32m  10362\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[1;32m  10363\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m  10364\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  10372\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[1;32m  10373\u001b[0m )\n\u001b[0;32m> 10374\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mapply()\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/apply.py:916\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[1;32m    914\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw(engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine, engine_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine_kwargs)\n\u001b[0;32m--> 916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_standard()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/apply.py:1063\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1061\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1062\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 1063\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_series_generator()\n\u001b[1;32m   1064\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1065\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_series_numba()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/apply.py:1081\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1078\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1079\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[1;32m   1080\u001b[0m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[0;32m-> 1081\u001b[0m         results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc(v, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs)\n\u001b[1;32m   1082\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[1;32m   1083\u001b[0m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[1;32m   1084\u001b[0m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[1;32m   1085\u001b[0m             results[i] \u001b[38;5;241m=\u001b[39m results[i]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[20], line 15\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(row)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Apply the function to get latitude and longitude\u001b[39;00m\n\u001b[1;32m     13\u001b[0m filtered_top_skills_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLatitude\u001b[39m\u001b[38;5;124m'\u001b[39m], filtered_top_skills_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLongitude\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;241m*\u001b[39mfiltered_top_skills_df\u001b[38;5;241m.\u001b[39mapply(\n\u001b[0;32m---> 15\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m row: get_coordinates(row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mJob Location City\u001b[39m\u001b[38;5;124m'\u001b[39m], row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mJob Location State\u001b[39m\u001b[38;5;124m'\u001b[39m]),\n\u001b[1;32m     16\u001b[0m         axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     17\u001b[0m     )\n\u001b[1;32m     18\u001b[0m )\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Drop rows where coordinates were not found\u001b[39;00m\n\u001b[1;32m     21\u001b[0m filtered_top_skills_df \u001b[38;5;241m=\u001b[39m filtered_top_skills_df\u001b[38;5;241m.\u001b[39mdropna(subset\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLatitude\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLongitude\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "Cell \u001b[0;32mIn[20], line 6\u001b[0m, in \u001b[0;36mget_coordinates\u001b[0;34m(city, state)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_coordinates\u001b[39m(city, state):\n\u001b[0;32m----> 6\u001b[0m     location \u001b[38;5;241m=\u001b[39m geolocator\u001b[38;5;241m.\u001b[39mgeocode(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcity\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstate\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, USA\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m location:\n\u001b[1;32m      8\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m location\u001b[38;5;241m.\u001b[39mlatitude, location\u001b[38;5;241m.\u001b[39mlongitude\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/geopy/geocoders/nominatim.py:297\u001b[0m, in \u001b[0;36mNominatim.geocode\u001b[0;34m(self, query, exactly_one, timeout, limit, addressdetails, language, geometry, extratags, country_codes, viewbox, bounded, featuretype, namedetails)\u001b[0m\n\u001b[1;32m    295\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.geocode: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, url)\n\u001b[1;32m    296\u001b[0m callback \u001b[38;5;241m=\u001b[39m partial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parse_json, exactly_one\u001b[38;5;241m=\u001b[39mexactly_one)\n\u001b[0;32m--> 297\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_geocoder(url, callback, timeout\u001b[38;5;241m=\u001b[39mtimeout)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/geopy/geocoders/base.py:388\u001b[0m, in \u001b[0;36mGeocoder._call_geocoder\u001b[0;34m(self, url, callback, timeout, is_json, headers)\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m callback(result)\n\u001b[1;32m    387\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m error:\n\u001b[0;32m--> 388\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_adapter_error_handler(error)\n\u001b[1;32m    389\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m res \u001b[38;5;129;01mis\u001b[39;00m NONE_RESULT:\n\u001b[1;32m    390\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/geopy/geocoders/base.py:411\u001b[0m, in \u001b[0;36mGeocoder._adapter_error_handler\u001b[0;34m(self, error)\u001b[0m\n\u001b[1;32m    407\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exc_cls(\n\u001b[1;32m    408\u001b[0m             \u001b[38;5;28mstr\u001b[39m(error), retry_after\u001b[38;5;241m=\u001b[39mget_retry_after(error\u001b[38;5;241m.\u001b[39mheaders)\n\u001b[1;32m    409\u001b[0m         ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merror\u001b[39;00m\n\u001b[1;32m    410\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 411\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exc_cls(\u001b[38;5;28mstr\u001b[39m(error)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merror\u001b[39;00m\n\u001b[1;32m    412\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    413\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_geocoder_exception_handler(error)\n",
      "\u001b[0;31mGeocoderInsufficientPrivileges\u001b[0m: Non-successful status code 403"
     ]
    }
   ],
   "source": [
    "# Initialize the geolocator\n",
    "geolocator = Nominatim(user_agent=\"geoapiExercises\")\n",
    "\n",
    "# Function to get coordinates\n",
    "def get_coordinates(city, state):\n",
    "    location = geolocator.geocode(f\"{city}, {state}, USA\")\n",
    "    if location:\n",
    "        return location.latitude, location.longitude\n",
    "    else:\n",
    "        return None, None\n",
    "\n",
    "# Apply the function to get latitude and longitude\n",
    "filtered_top_skills_df['Latitude'], filtered_top_skills_df['Longitude'] = zip(\n",
    "    *filtered_top_skills_df.apply(\n",
    "        lambda row: get_coordinates(row['Job Location City'], row['Job Location State']),\n",
    "        axis=1\n",
    "    )\n",
    ")\n",
    "\n",
    "# Drop rows where coordinates were not found\n",
    "filtered_top_skills_df = filtered_top_skills_df.dropna(subset=['Latitude', 'Longitude'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "56c90867-8708-41e4-a036-68ff4cbeaed5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Value of 'lat' is not the name of a column in 'data_frame'. Expected one of ['Job Title', 'Company', 'Job Location', 'Job Location City', 'Job Location State', 'Job Posting Seen', 'Country', 'Position', 'Job Level', 'Job Type', 'Job Skills'] but received: Latitude",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Create a scatter map to show demand for analytics skills by city\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m fig \u001b[38;5;241m=\u001b[39m px\u001b[38;5;241m.\u001b[39mscatter_mapbox(\n\u001b[1;32m      3\u001b[0m     filtered_top_skills_df,\n\u001b[1;32m      4\u001b[0m     lat\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLatitude\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      5\u001b[0m     lon\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLongitude\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      6\u001b[0m     hover_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mJob Location City\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      7\u001b[0m     hover_data\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mJob Skills\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m      8\u001b[0m     color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mJob Skills\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      9\u001b[0m     size_max\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m15\u001b[39m,\n\u001b[1;32m     10\u001b[0m     zoom\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,\n\u001b[1;32m     11\u001b[0m     height\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m600\u001b[39m,\n\u001b[1;32m     12\u001b[0m     mapbox_style\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcarto-positron\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     13\u001b[0m )\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Show the map\u001b[39;00m\n\u001b[1;32m     16\u001b[0m fig\u001b[38;5;241m.\u001b[39mshow()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/plotly/express/_chart_types.py:1247\u001b[0m, in \u001b[0;36mscatter_mapbox\u001b[0;34m(data_frame, lat, lon, color, text, hover_name, hover_data, custom_data, size, animation_frame, animation_group, category_orders, labels, color_discrete_sequence, color_discrete_map, color_continuous_scale, range_color, color_continuous_midpoint, opacity, size_max, zoom, center, mapbox_style, title, template, width, height)\u001b[0m\n\u001b[1;32m   1214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mscatter_mapbox\u001b[39m(\n\u001b[1;32m   1215\u001b[0m     data_frame\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1216\u001b[0m     lat\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1241\u001b[0m     height\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1242\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m go\u001b[38;5;241m.\u001b[39mFigure:\n\u001b[1;32m   1243\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1244\u001b[0m \u001b[38;5;124;03m    In a Mapbox scatter plot, each row of `data_frame` is represented by a\u001b[39;00m\n\u001b[1;32m   1245\u001b[0m \u001b[38;5;124;03m    symbol mark on a Mapbox map.\u001b[39;00m\n\u001b[1;32m   1246\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1247\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m make_figure(args\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlocals\u001b[39m(), constructor\u001b[38;5;241m=\u001b[39mgo\u001b[38;5;241m.\u001b[39mScattermapbox)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/plotly/express/_core.py:2090\u001b[0m, in \u001b[0;36mmake_figure\u001b[0;34m(args, constructor, trace_patch, layout_patch)\u001b[0m\n\u001b[1;32m   2087\u001b[0m layout_patch \u001b[38;5;241m=\u001b[39m layout_patch \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[1;32m   2088\u001b[0m apply_default_cascade(args)\n\u001b[0;32m-> 2090\u001b[0m args \u001b[38;5;241m=\u001b[39m build_dataframe(args, constructor)\n\u001b[1;32m   2091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m constructor \u001b[38;5;129;01min\u001b[39;00m [go\u001b[38;5;241m.\u001b[39mTreemap, go\u001b[38;5;241m.\u001b[39mSunburst, go\u001b[38;5;241m.\u001b[39mIcicle] \u001b[38;5;129;01mand\u001b[39;00m args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpath\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2092\u001b[0m     args \u001b[38;5;241m=\u001b[39m process_dataframe_hierarchy(args)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/plotly/express/_core.py:1492\u001b[0m, in \u001b[0;36mbuild_dataframe\u001b[0;34m(args, constructor)\u001b[0m\n\u001b[1;32m   1489\u001b[0m     args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolor\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1490\u001b[0m \u001b[38;5;66;03m# now that things have been prepped, we do the systematic rewriting of `args`\u001b[39;00m\n\u001b[0;32m-> 1492\u001b[0m df_output, wide_id_vars \u001b[38;5;241m=\u001b[39m process_args_into_dataframe(\n\u001b[1;32m   1493\u001b[0m     args, wide_mode, var_name, value_name\n\u001b[1;32m   1494\u001b[0m )\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# now that `df_output` exists and `args` contains only references, we complete\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# the special-case and wide-mode handling by further rewriting args and/or mutating\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;66;03m# df_output\u001b[39;00m\n\u001b[1;32m   1500\u001b[0m count_name \u001b[38;5;241m=\u001b[39m _escape_col_name(df_output, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcount\u001b[39m\u001b[38;5;124m\"\u001b[39m, [var_name, value_name])\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/plotly/express/_core.py:1213\u001b[0m, in \u001b[0;36mprocess_args_into_dataframe\u001b[0;34m(args, wide_mode, var_name, value_name)\u001b[0m\n\u001b[1;32m   1211\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m argument \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1212\u001b[0m             err_msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m To use the index, pass it in directly as `df.index`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1213\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(err_msg)\n\u001b[1;32m   1214\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m length \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(df_input[argument]) \u001b[38;5;241m!=\u001b[39m length:\n\u001b[1;32m   1215\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1216\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll arguments should have the same length. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1217\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe length of column argument `df[\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m]` is \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m, whereas the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1224\u001b[0m         )\n\u001b[1;32m   1225\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Value of 'lat' is not the name of a column in 'data_frame'. Expected one of ['Job Title', 'Company', 'Job Location', 'Job Location City', 'Job Location State', 'Job Posting Seen', 'Country', 'Position', 'Job Level', 'Job Type', 'Job Skills'] but received: Latitude"
     ]
    }
   ],
   "source": [
    "# Create a scatter map to show demand for analytics skills by city\n",
    "fig = px.scatter_mapbox(\n",
    "    filtered_top_skills_df,\n",
    "    lat='Latitude',\n",
    "    lon='Longitude',\n",
    "    hover_name='Job Location City',\n",
    "    hover_data=['Job Skills'],\n",
    "    color='Job Skills',\n",
    "    size_max=15,\n",
    "    zoom=3,\n",
    "    height=600,\n",
    "    mapbox_style='carto-positron'\n",
    ")\n",
    "\n",
    "# Show the map\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c907be34-63f6-4db4-8a8e-4573be19cc9b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
